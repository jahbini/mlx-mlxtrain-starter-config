run:
  seed: 42
  alt_seed: 7
  output_dir: "run"              # replaces OUT_DIR

experiments:
  - microsoft/Phi-3-mini-4k-instruct
  - TinyLlama/TinyLlama-1.1B-Chat-v1.0

paths:                            # replaces *_PATH constants
  tokenizer: "tokenizer_meta"
  
snapshot:
  output_dir: "snapshots"
  fused:  "fused/model"
  quant:  "quantized"
  max_new:  128
  seed:  7
  n_shots:  3
  min_words:  3
  retries:  2
  prompts:
   - "Tell us who lives in the house of the three gunas."
   - "Offer a short proverb on patience."
   - "Give a hopeful saying for a widow."

sanity:
  prompts:
   - "Share a saying about luck."
   - "Offer a short proverb on patience."
   - "Give a hopeful saying for a widow."

eval:
  generations: "generations"
  output_dir: "eval_out"
  ablations: "ablation_generations"
  report: "report.md"
  policy: "generation_policy.json"
  recreate: "repro.sh"
  analysis: "eos_analysis"
  summary: "eos_summary"

web:
  base: "stjohnsjim.com"
  content_id: "bloviation"
  user_agent: "SJJ-JSONL/voice-continuer/1.0"
  request_timeout: 20
  pause_sec: 0.5
  valid_fraction: 0.2
  min_story_words: 120              # skip tiny pages
  min_prompt_words: 100             # prompt lower bound
  max_prompt_words: 300             # prompt upper bound
  min_completion_words: 40          # completion lower bound
  max_completion_words: 160         # completion upper bound
  max_examples_per_story: 6         # cap examples per story
  
data:
  output_dir: "run/data"              # replaces OUT_DIR
  experiments_csv: "experiments.csv"
  artifacts: "artifacts.json"
  contract: "data_contract.json"
  policy:   "format_policy.json"
  catalog:  "data_catalog.json"
  report:   "data_report.json"
  hf_dataset: "asuender/motivational-quotes"
  subset: "quotes"
  mode: "sft"
  valid_fraction: 0.02
  min_words: 5
  max_words: 60
  format:
    mode: plain            # or sft
    prompt_key: prompt     # required if mode == sft
    completion_key: completion
  split:
    valid_fraction: 0.02

model:
  name: "microsoft/Phi-4-reasoning-plus"
  dtype: "float16"
  context_length: 8192

trainer:                          # global defaults
  epochs: 1
  batch_size: 1
  grad_accum: 8
  max_seq_length: 512
  learning_rate: 0.0002
  bf16: true
  iters_override: 0               # 0 = auto-calc

sweep:                            # step 6 “experiment matrix”
  base_models:
    - "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    # - "mlx-community/phi-2"
  # Optional per-sweep overrides (fallback to trainer.* when absent)
  hyperparams: {}

crawl:
  mode: urls               # or files
  urls:
    seeds_path: seeds.txt
    max_pages: 50
    user_agent: "Mozilla/5.0 (MLX-Voice-Crawl)"
    timeout: 15
  files:
    glob: "source_html/*.html"   # used when mode: files
  filters:
    min_words: 5
    max_words: 6000
