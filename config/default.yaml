# ============================================================
# Celarien / SpaceStruts Pipeline Configuration
# Unified CoffeeScript-compatible schema
# ============================================================

run:
  output_dir: out
  snapshot_dir: ./snapshots
  data_dir: ./data
  eval_dir: eval_out
  contract: data_contract.json
  catalog: data_catalog.json
  experiments_csv: experiments.csv
  model: microsoft/Phi-3-mini-4k-instruct
  format_policy: data/format_policy.json
  policy: generation_policy.json
  report: data_report.json
  fused_dir: ./fused_model
  generations: generations
  tokmeta: tokenizer_meta
  ablations: ablation_generations
  artifacts: artifacts.json
  summary: summary
  analysis: analysis
  contract: data_contract.json
  prompt_policy: prompt_policy.json
  artifacts: artifacts.json

oracle_chat:
  run: scripts/095_oracle_chat.coffee

entropy:
  run: scripts/115_entropy.coffee
  params:
    max_new_tokens: 128
    stop_strings: ["\n\n", "==="]

crawl_for_voice:
  run: scripts/081_crawl_for_voice.coffee
  base: celarien.com
  valid_fraction: 0.1
  min_story_words: 50
  max_pages: 1000
  pause_sec: 0.5
  user_agent: Mozilla/5.0
  request_timeout: 15000

sanity:
  ablations: ablations

examination:
  prompts:
    - "Share an important thought."
    - "What truth do we often overlook?"
  max_new_short: 64
  max_new_long: 128
  only_model_id: ""
  ablations: ablations

fuse:
  do_fuse: true
  q_bits: 4
  q_group: 32
  dtype: float16
  dry_run: false

prepare_prompts:
  template_name: icl_minimal
  stop_strings: ["<|endoftext|>", "\n\n"]
  use_eos_token: false

prepare_outmd_kag:
  input_md: your/your.md
  output_jsonl: out_kag.jsonl

eval:
  ablations: ablations
  report: report.md
  policy: generation_policy.json

snapshot:
  prompts:
    - "Finish this proverb: 'A stitch in time...'"
    - "What lesson would a wise elder share about patience?"
  max_new: 64
  alt_seed: 123
  n_shots: 3
  min_words: 4
  retries: 3

data:
  output_dir: ./data
  contract: data_contract.json
  catalog: data_catalog.json
  report: data_report.json

eval:
  output_dir: eval_out
  policy: generation_policy.json
  generations: generations.jsonl

fetch_hf_dataset:
  desc: "Download and preprocess a HuggingFace dataset for fine-tuning."
  run: scripts/01_fetch_hf_dataset.coffee

  # --- Required parameters (no runtime defaults) ---
  hf_dataset: asuender/motivational-quotes
  subset: quotes
  mode: plain
  valid_fract: 0.10
  min_words: 5
  max_words: 60
  seed: 42

train:
  dry_run: false
  only_model_id: ""
  only_row: "None"
  steps_per_report: 0
  steps_per_eval: 0
  val_batches: 0
